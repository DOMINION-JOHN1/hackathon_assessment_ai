{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install requests\n",
    "!pip install --upgrade langchain-core\n",
    "!pip install langchain_openai\n",
    "!pip install openai\n",
    "!pip install langchain_community\n",
    "!pip install pypdf"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3Mm6veEk4Eq",
    "outputId": "5d963374-17c0-45ae-8c99-760f30f450bc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core)\n",
      "  Downloading langsmith-0.1.110-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.8.2)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.75->langchain-core)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core)\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.4/50.4 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.20.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (3.8)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core) (2.0.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core) (1.2.2)\n",
      "Downloading langchain_core-0.2.38-py3-none-any.whl (396 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m396.4/396.4 kB\u001B[0m \u001B[31m18.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.110-py3-none-any.whl (288 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m288.4/288.4 kB\u001B[0m \u001B[31m21.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.4/76.4 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m141.9/141.9 kB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, langchain-core\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.38 langsmith-0.1.110 orjson-3.10.7 tenacity-8.5.0\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.38)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n",
      "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (0.1.110)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.8)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.35->langchain_openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.35->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.35->langchain_openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
      "Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.0/52.0 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m365.7/365.7 kB\u001B[0m \u001B[31m15.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m42.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m318.9/318.9 kB\u001B[0m \u001B[31m21.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: jiter, tiktoken, openai, langchain_openai\n",
      "Successfully installed jiter-0.5.0 langchain_openai-0.1.23 openai-1.43.0 tiktoken-0.7.0\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.43.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.16 (from langchain_community)\n",
      "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.110)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.16->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n",
      "Downloading langchain_community-0.2.16-py3-none-any.whl (2.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m41.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m50.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.3/49.3 kB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-0.2.16 langchain-text-splitters-0.2.4 langchain_community-0.2.16 marshmallow-3.22.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m295.8/295.8 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-4.3.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import nbformat\n",
    "#from openai import OpenAI"
   ],
   "metadata": {
    "id": "YuuGuvHrk1n7",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "api_key = userdata.get('datarango_rag')"
   ],
   "metadata": {
    "id": "__fHGZ_NmvQ_",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "model = ChatOpenAI(openai_api_key = api_key, model=\"gpt-3.5-turbo\")"
   ],
   "metadata": {
    "id": "CkTunQhHm-LU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def read_notebook(notebook_path):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    content = \"\"\n",
    "    for cell in nb.cells:\n",
    "          if cell.cell_type == 'markdown':\n",
    "              content += cell.source + \"\\n\\n\"\n",
    "          elif cell.cell_type == 'code':\n",
    "              content += f\"```python\\n{cell.source}\\n```\\n\\n\"\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "content = read_notebook(\"/content/mentalyc_poc.ipynb\")"
   ],
   "metadata": {
    "id": "_ixPhVkRnDgV",
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "def analyze_with_llm(content):\n",
    "    prompt = \"\"\"\n",
    "    Analyze the following Jupyter notebook content and provide scores (0-20) and detailed feedback for each of these criteria:\n",
    "    1. Technical accuracy\n",
    "    2. Business understanding\n",
    "    3. AI justification\n",
    "    4. Code quality\n",
    "    5. Documentation\n",
    "    After which you should provide a total score  in percetage (which is a sum of all the scores for each criterion)\n",
    "    For each criterion, explain why you gave that score and provide specific suggestions for improvement.\n",
    "\n",
    "    Technical accuracy (score):\n",
    "    Explanation and suggestions\n",
    "    Business understanding (score):\n",
    "    Explanation and suggestions\n",
    "    AI justification (score):\n",
    "    Explanation and suggestions\n",
    "    Code quality (score):\n",
    "    Explanation and suggestions\n",
    "    Documentation (score):\n",
    "    Explanation and suggestions\n",
    "\n",
    "    Total score: Total score in percentage\n",
    "    Overall explanation: Overall explanation\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt)\n",
    "\n",
    "\n",
    "    formatted_prompt = prompt.format(context = \"Ensure to follow every instructions in prompt\", question = \"Here is the notebook for review\" + content )\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "tJh7FaZkn-K_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = analyze_with_llm(content)"
   ],
   "metadata": {
    "id": "KAR6midNvEyZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(result.content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2y-PAfsbsRJB",
    "outputId": "5d8d25d7-baa9-451a-9063-1980447d3473",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Technical accuracy (16):\n",
      "The code in the Jupyter notebook demonstrates a good level of technical accuracy. The data preprocessing steps are correctly implemented, and the machine learning model is trained and evaluated properly. However, there could be some improvements in the way hyperparameters are tuned and the model is validated.\n",
      "\n",
      "Business understanding (14):\n",
      "The notebook lacks a clear explanation of the business problem being addressed and the potential impact of the machine learning model. Providing more context on the dataset and the problem domain would greatly improve the business understanding score.\n",
      "\n",
      "AI justification (15):\n",
      "The justification for using a machine learning model is present in the notebook, but it could be more detailed. Explaining why a specific algorithm was chosen and how it relates to the problem at hand would strengthen the AI justification score.\n",
      "\n",
      "Code quality (17):\n",
      "The code in the notebook is well-structured and easy to follow. Comments are used effectively to explain the purpose of each code block. However, there could be more modularization of code and better error handling to enhance the code quality.\n",
      "\n",
      "Documentation (13):\n",
      "The documentation in the notebook is sufficient but could be improved. More explanations about the data, model, and results would be beneficial. Additionally, including a summary of key findings and next steps would enhance the documentation score.\n",
      "\n",
      "Total score: 75%\n",
      "Overall explanation: The Jupyter notebook demonstrates a good level of technical accuracy and code quality. However, there are areas for improvement in terms of providing more business context, justifying the use of AI more thoroughly, and enhancing the documentation throughout the notebook. Making these improvements would result in a higher overall score.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result_dict = result.__dict__\n",
    "print(result_dict['content'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDREvEjWsnHH",
    "outputId": "670a46c6-1a75-4238-b7f2-a45e11295d42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "    \"technical_accuracy\": 7,\n",
      "    \"business_understanding\": 6,\n",
      "    \"ai_justification\": 8,\n",
      "    \"code_quality\": 5,\n",
      "    \"documentation\": 6,\n",
      "    \"detailed_feedback\": {\n",
      "        \"technical_accuracy\": \"The technical content is mostly accurate, but there are a few minor errors or inconsistencies that could be addressed. Suggest double-checking calculations and data processing steps for accuracy.\",\n",
      "        \"business_understanding\": \"There is a basic understanding of the business problem, but more detailed analysis or explanation of the business context and impact of the AI solution could be beneficial.\",\n",
      "        \"ai_justification\": \"The justification for using AI in the solution is clear and relevant to the problem at hand. However, providing more details on the choice of specific AI techniques or models could strengthen the justification.\",\n",
      "        \"code_quality\": \"The code is functional and achieves the desired outcome, but it could be improved in terms of readability, efficiency, and adherence to best practices. Suggest refactoring code to make it more modular and adding comments for better understanding.\",\n",
      "        \"documentation\": \"The documentation provides a good overview of the project, but more detailed explanations of the code, data sources, and methodology would enhance the overall quality. Suggest including a README file with instructions on how to run the code and explanations of key components.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "result_dict = json.dumps(result['content'], indent = 4)\n",
    "print(result_dict['content'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "_q1gG_Y4tYof",
    "outputId": "75362eac-8b9c-4583-e5f5-a7948271f7ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'AIMessage' object is not subscriptable",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-0d97410ee22c>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mresult_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'content'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'content'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'AIMessage' object is not subscriptable"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result_dict = result.__dict__\n",
    "print(result_dict['content'][\"technical_accuracy\"])\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YN_V8cD2aXff",
    "outputId": "3be40cea-7323-4cd8-976b-25fff35db41e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "    \"technical_accuracy\": 7,\n",
      "    \"business_understanding\": 6,\n",
      "    \"ai_justification\": 8,\n",
      "    \"code_quality\": 5,\n",
      "    \"documentation\": 6,\n",
      "    \"detailed_feedback\": {\n",
      "        \"technical_accuracy\": \"The technical content is mostly accurate, but there are some minor errors or oversights that could be addressed to improve accuracy.\",\n",
      "        \"business_understanding\": \"There is a basic understanding of the business context, but more depth and analysis could be included to enhance the business understanding.\",\n",
      "        \"ai_justification\": \"The justification for using AI is well-explained and relevant to the problem at hand.\",\n",
      "        \"code_quality\": \"The code quality could be improved by following better coding practices, such as proper variable naming, code organization, and comments for better readability and maintainability.\",\n",
      "        \"documentation\": \"The documentation is sufficient but could benefit from more detailed explanations of the code and the reasoning behind certain decisions.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(result_dict['content'][:30])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viOPMEN9dC9H",
    "outputId": "3520d8f2-9e94-41a3-b948-6562791c6fbe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "    \"technical_accuracy\": 7,\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW5JEvBXkomo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print (parser.parse(result.content))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZH7DcDZwWfm",
    "outputId": "a240d3f4-9a2e-4e64-cdd9-6c960535c93f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "    \"technical_accuracy\": 7,\n",
      "    \"business_understanding\": 6,\n",
      "    \"ai_justification\": 5,\n",
      "    \"code_quality\": 6,\n",
      "    \"documentation\": 7,\n",
      "    \"detailed_feedback\": {\n",
      "        \"technical_accuracy\": \"The code demonstrates a good level of technical accuracy with correct implementation of machine learning algorithms and data preprocessing techniques. However, there are some areas where optimization and fine-tuning could be improved.\",\n",
      "        \"business_understanding\": \"The notebook shows a decent understanding of the business problem and the relevance of the data used. However, more in-depth analysis of how the model can impact business decisions and outcomes could be beneficial.\",\n",
      "        \"ai_justification\": \"The justification for using the specific machine learning algorithms is somewhat lacking. More explanation on why certain algorithms were chosen over others based on the problem requirements and data characteristics would enhance the AI justification.\",\n",
      "        \"code_quality\": \"The code quality is sufficient with clear variable naming and organized structure. However, there are some areas where comments or docstrings could be added for better readability and understanding.\",\n",
      "        \"documentation\": \"The documentation is fairly good with explanations of the code blocks and data processing steps. Including more details on the model evaluation metrics and how they impact the model performance would further improve the documentation.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class AIFeedbackSystem:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def read_notebook(self, notebook_path):\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "        content = \"\"\n",
    "        for cell in nb.cells:\n",
    "            if cell.cell_type == 'markdown':\n",
    "                content += cell.source + \"\\n\\n\"\n",
    "            elif cell.cell_type == 'code':\n",
    "                content += f\"```python\\n{cell.source}\\n```\\n\\n\"\n",
    "\n",
    "        return content\n",
    "\n",
    "\n",
    "    def analyze_with_llm(self, content):\n",
    "        prompt = \"\"\"\n",
    "        Analyze the following Jupyter notebook content and provide scores (0-20), and detailed feedback for each of these criteria:\n",
    "        1. Technical accuracy\n",
    "        2. Business understanding\n",
    "        3. AI justification\n",
    "        4. Code quality\n",
    "        5. Documentation (especially for non-technical managers)\n",
    "\n",
    "        After which you should provide a total score which is a sum of all the scores.\n",
    "\n",
    "        For each criterion, explain why you gave that score and provide specific suggestions for improvement.\n",
    "\n",
    "        Notebook content:\n",
    "        {content}\n",
    "\n",
    "        Respond in the following JSON format:\n",
    "        {\n",
    "            \"technical_accuracy\": score,\n",
    "            \"business_understanding\": score,\n",
    "            \"ai_justification\": score,\n",
    "            \"code_quality\": score,\n",
    "            \"documentation\": score,\n",
    "            \"detailed_feedback\": {{\n",
    "                \"technical_accuracy\": \"explanation and suggestions\",\n",
    "                \"business_understanding\": \"explanation and suggestions\",\n",
    "                \"ai_justification\": \"explanation and suggestions\",\n",
    "                \"code_quality\": \"explanation and suggestions\",\n",
    "                \"documentation\": \"explanation and suggestions\"\n",
    "            }}\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an AI expert tasked with evaluating Jupyter notebooks.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_feedback(self, scores, detailed_feedback):\n",
    "        feedback = \"Feedback:\\n\"\n",
    "        for criterion, score in scores.items():\n",
    "            feedback += f\"{criterion.replace('_', ' ').title()}: {score:.2f}\\n\"\n",
    "            feedback += f\"  {detailed_feedback[criterion]}\\n\\n\"\n",
    "        return feedback\n",
    "\n",
    "\n",
    "    def evaluate_notebook(self, notebook_path):\n",
    "        notebook_content = self.read_notebook(notebook_path)\n",
    "        llm_analysis = self.analyze_with_llm(notebook_content)\n",
    "\n",
    "        scores = {\n",
    "            'technical_accuracy': llm_analysis['technical_accuracy'],\n",
    "            'business_understanding': llm_analysis['business_understanding'],\n",
    "            'ai_justification': llm_analysis['ai_justification'],\n",
    "            'code_quality': llm_analysis['code_quality'],\n",
    "            'documentation': llm_analysis['documentation']\n",
    "        }\n",
    "\n",
    "        return scores, self.generate_feedback(scores, llm_analysis['detailed_feedback'])\n",
    "\n",
    "\n",
    "# Usage example\n",
    "api_key = api_key\n",
    "feedback_system = AIFeedbackSystem(api_key)\n",
    "scores, feedback = feedback_system.evaluate_notebook(\"/content/data_rango_chatbot.ipynb\")\n",
    "print(feedback)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "kYceoSjDwW7V",
    "outputId": "9cd8a9ec-d220-4cdd-8dfe-b54c48bfc215",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-494c54048890>\u001B[0m in \u001B[0;36m<cell line: 84>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0mapi_key\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapi_key\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[0mfeedback_system\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAIFeedbackSystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapi_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeedback\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeedback_system\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate_notebook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/content/data_rango_chatbot.ipynb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeedback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-494c54048890>\u001B[0m in \u001B[0;36mevaluate_notebook\u001B[0;34m(self, notebook_path)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         scores = {\n\u001B[0;32m---> 71\u001B[0;31m             \u001B[0;34m'technical_accuracy'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mllm_analysis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'technical_accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m             \u001B[0;34m'business_understanding'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mllm_analysis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'business_understanding'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m             \u001B[0;34m'ai_justification'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mllm_analysis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ai_justification'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: string indices must be integers"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "oTwFL_21V-gJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}